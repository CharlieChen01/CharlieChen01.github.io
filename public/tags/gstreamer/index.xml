<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>GStreamer on 👨‍🌾 Charlie Chen</title>
    <link>http://localhost:1313/tags/gstreamer/</link>
    <description>Recent content in GStreamer on 👨‍🌾 Charlie Chen</description>
    <generator>Hugo -- 0.124.1</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 May 2024 17:43:51 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/gstreamer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GStreamer Pipeline for Playing WebM URLs</title>
      <link>http://localhost:1313/posts/media/gstreamer-pipeline-for-playing-webm-urls/</link>
      <pubDate>Wed, 08 May 2024 17:43:51 +0800</pubDate>
      <guid>http://localhost:1313/posts/media/gstreamer-pipeline-for-playing-webm-urls/</guid>
      <description>GStreamer 播放一个 WebM 视频文件 #include &amp;lt;gst/gst.h&amp;gt; int main (int argc, char *argv[]) { GstElement *pipeline; GstBus *bus; GstMessage *msg; /* Initialize GStreamer */ gst_init (&amp;amp;argc, &amp;amp;argv); /* Build the pipeline */ pipeline = gst_parse_launch (&amp;#34;playbin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm&amp;#34;, NULL); /* Start playing */ gst_element_set_state (pipeline, GST_STATE_PLAYING); /* Wait until error or EOS */ bus = gst_element_get_bus (pipeline); msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_ERROR | GST_MESSAGE_EOS); /* Free resources */ if (msg != NULL) gst_message_unref (msg); gst_object_unref (bus); gst_element_set_state (pipeline, GST_STATE_NULL); gst_object_unref (pipeline); return 0; } 这段代码使用了 GStreamer 库来播放一个 WebM 视频文件。让我逐步解释一下每个部分的作用：</description>
    </item>
    <item>
      <title>About Gstreamer Misc(deinterlace Videorate Videocrop)</title>
      <link>http://localhost:1313/posts/media/about-gstreamer-miscdeinterlace-videorate-videocrop/</link>
      <pubDate>Tue, 07 May 2024 16:46:46 +0800</pubDate>
      <guid>http://localhost:1313/posts/media/about-gstreamer-miscdeinterlace-videorate-videocrop/</guid>
      <description>在 GStreamer 中，deinterlace（场帧处理）、videorate（帧率转换）和 videocrop（视频截取）是处理视频流的重要元素：
deinterlace（场帧处理）: 功能: deinterlace 元素用于将交错视频帧转换为逐行扫描的视频帧。这个过程涉及到不同的算法，可以根据需要选择，以提供不同的质量和 CPU 使用率 1。 使用示例:
gst-launch-1.0 -v filesrc location=/path/to/file ! decodebin ! videoconvert ! deinterlace ! videoconvert ! autovideosink
这个管道使用默认的去交错选项去交错视频文件。
videorate（帧率转换）: 功能: videorate 元素接收一个带有时间戳的视频帧流，并产生一个与源端口帧率匹配的完美流。它通过丢弃和复制帧来进行校正，目前还没有使用复杂算法来插值帧 2。 使用示例:
gst-launch-1.0 -v uridecodebin uri=file:///path/to/video.ogg ! videoconvert ! videoscale ! videorate ! video/x-raw,framerate=15/1 ! autovideosink
这个管道解码视频文件并将帧率调整为 15fps 再播放。
videocrop（视频截取）: 功能: videocrop 元素用于裁剪视频帧，即它可以移除图像左侧、右侧、顶部或底部的部分，并输出一个比输入图像小的图像，去除了边缘不需要的部分 3。 使用示例:
gst-launch-1.0 -v videotestsrc ! videocrop top=42 left=1 right=4 bottom=0 ! ximagesink
这个管道从测试视频源裁剪出一部分并显示。
这些元素在视频处理中非常有用，可以用于视频编辑、格式转换或流媒体传输等多种场景。</description>
    </item>
    <item>
      <title>About Video Processing and Hardware Acceleration in Gstreamer</title>
      <link>http://localhost:1313/posts/media/about-video-processing-and-hardware-acceleration-in-gstreamer/</link>
      <pubDate>Tue, 07 May 2024 15:28:15 +0800</pubDate>
      <guid>http://localhost:1313/posts/media/about-video-processing-and-hardware-acceleration-in-gstreamer/</guid>
      <description>关于 Gstreamer 中的视频处理与硬件加速 &amp;ndash;节选自《LiveVideoStackCon2022 上海站大会， 英特尔加速计算系统与图形部工程师何俊彦，Gstreamer 的框架和特点，视频的模块化处理，以及其硬件加速的实现与应用案例》
Basic Idea 这是 Gstreamer 中一个 element 的基本形式。两端的 pad 来负责输入和输出，而由当中的 element 来完成具体工作。比如一个 decoder，输入是 H264 的码流，输出则是 decoded 数据，也就是我们常说的视频帧，所以此处的 element 就可以实现为一个完整的 H264 的解码器。该解码器的实现可以是一个完整的内部实现，也可以封装已有的外部解码器来实现。比如，我们可以把 OpenH264 项目 build 成 library 的形式并适当封装，在此 element 中直接调用，从而实现该 H264 解码器插件的功能。
我们可以发现，这里的输入输出格式是非常随意的，甚至输入可以是 video，输出是 audio，这就使插件的设计有了更大更灵活的空间。比如我们录取了一个视频，视频里的每一帧都是拍的某本书的一页，于是我们可以设计这样一个 pipeline，其中一个 element 将 video 转换成 text，然后连接另一个 element，其接受 text 输入，并用语音将其全部读出并输出 audio，从而完成了将整本书转成 audio 的功能。这些 element 的设计方式在 Gstreamer 是被完全允许的。当然，FFmpeg 也能完成上述功能，但在提交代码到社区和 upstream 过程中会有遇到很大的麻烦和挑战，因为这种 video 转 text 或者 text 转 audio 的模式，在 FFmpeg 中并没有现成的归类，也许需要你提出新的 filter 类型或新的模式。 这是更多 element 的类型，demuxer 对应 FFmpeg 里的 av input format，source element 对应于 FFmpeg 里的 URL，用来产生源输入，filter element 则对应于 FFmpeg 里的 filter。总的来说，这些内容有与 FFmpeg 相似的地方，但是会以 element 的形式进行管理，最后用 pipeline 将这些内容连接在一起，由第一个向最后一个推送数据。 在电子技术（特别是数字电路）中，数据选择器（英语：Data Selector），或称多路复用器（英语：multiplexer，简称：MUX）是一种可以从多个模拟或数字输入信号中选择一个信号进行输出的器件&amp;gt; 1。一个有 2^n 输入端的数据选择器有 n 个可选择的输入-输出线路，可以通过控制端来选择其中一个信号作为输出 1。数据选择器主要用于增加一定量的时间和带宽内的可以通过网络发送的数据量 1。它使&amp;gt; 多个信号共享一个设备或资源，例如一个模拟数字转换器或一个传输线，而不必给每一个输入信号配备一个设备。</description>
    </item>
    <item>
      <title>Diffrences and Similarities Between Gstreamer and FFmpeg</title>
      <link>http://localhost:1313/posts/media/diffrences-and-similarities-between-gstreamer-and-ffmpeg/</link>
      <pubDate>Tue, 07 May 2024 14:45:14 +0800</pubDate>
      <guid>http://localhost:1313/posts/media/diffrences-and-similarities-between-gstreamer-and-ffmpeg/</guid>
      <description>FFmpeg 和 GStreamer 都是开源的多媒体框架，它们在处理音频和视频方面有着广泛的应用。两者都提供了强大的工具和库，用于编码、解码、转码、流处理等多媒体操作。以下是对 FFmpeg 和 GStreamer 的深入对比和各自的应用场景：
FFmpeg FFmpeg 是一个跨平台的解决方案，用于录制、转换数字音视频，并将其转换成不同的格式。它包含了 libavcodec ，这是一个用于多个项目音视频编解码的领先库。FFmpeg 在 Linux 平台下开发，但它可以在包括 Windows 在内的大多数操作系统中编译。
特点：
高性能：FFmpeg 以其极快的编解码速度而闻名。 广泛的格式支持：支持几乎所有已知的音视频格式。 命令行工具：提供了丰富的命令行工具，方便用户直接操作。 库支持：可以作为库嵌入到其他程序中，用于开发多媒体应用程序。 应用场景：
视频转码：在需要将视频从一种格式转换为另一种格式时，FFmpeg 是首选工具。 流媒体服务器：作为流媒体服务器的一部分，用于实时转码和流处理。 视频编辑软件：许多视频编辑软件使用 FFmpeg 作为其编解码器库。 GStreamer GStreamer 是一个基于流水线的多媒体框架，用于创建流媒体应用程序。它的设计理念是基于插件的架构，允许开发者轻松地添加新的编解码器和功能。
特点：
模块化：GStreamer 的插件架构使得扩展功能变得简单。 管道模型：使用元素（elements）和管道（pipelines）来构建复杂的多媒体处理流程。 跨平台：支持多种操作系统，包括 Linux、Windows 和 macOS。 可编程性：提供了丰富的 API，适合开发复杂的应用程序。 应用场景：
多媒体播放器：GStreamer 常用于开发多媒体播放器，因其灵活性和可扩展性。 实时音视频处理：在需要实时处理音视频数据的应用中，如视频会议系统。 嵌入式系统：由于其模块化设计，GStreamer 在资源受限的嵌入式系统中也有应用。 对比 性能：FFmpeg 在编解码性能上通常优于 GStreamer，特别是在处理特定格式时。 灵活性：GStreamer 的管道模型提供了更高的灵活性，适合构建复杂的处理流程。 易用性：FFmpeg 的命令行工具通常更易于使用，而 GStreamer 可能需要更多的编程知识。 社区与生态：两者都有活跃的社区，但 FFmpeg 的社区可能更大一些，而 GStreamer 在某些特定领域（如 Linux 桌面环境）有更深的根植。 选择 FFmpeg 还是 GStreamer 取决于具体的应用需求。如果需要快速、高效地处理音视频文件，FFmpeg 可能是更好的选择。如果项目需要高度的灵活性和可扩展性，GStreamer 可能更适合。在实际应用中，两者甚至可以结合使用，以发挥各自的优势。</description>
    </item>
  </channel>
</rss>
